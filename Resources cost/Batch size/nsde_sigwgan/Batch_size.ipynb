{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8783cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if is_cuda else 'cpu'\n",
    "if not is_cuda:\n",
    "    print(\"Warning: CUDA not available; falling back to CPU but this is likely to be very slow.\")\n",
    "    \n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94a4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.Signature import Signature, Basepoint, sig_lreg, Cumsum2\n",
    "from lib.Utilities import get_n_params\n",
    "from lib.NSDE import SigNSDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6477c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('../../../AR/data/data.pt')\n",
    "\n",
    "for dataset in data:\n",
    "    data[dataset] = data[dataset].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf2d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_X = Signature(depth=5, augmentations = [Basepoint, Cumsum2], \n",
    "                  data_size=data['X_train'].shape[2],\n",
    "                  interval=[0, data['X_train'].shape[1]+1], \n",
    "                  q=1, \n",
    "                  t_norm = data['X_train'][:, :, 0].max()).to(device)\n",
    "\n",
    "sig_Y = Signature(depth=4, augmentations = [Cumsum2], \n",
    "                  data_size=data['Y_train'].shape[2],\n",
    "                  interval=[0, data['Y_train'].shape[1]+1], \n",
    "                  q=1, \n",
    "                  t_norm = data['Y_train'][:, :, 0].max()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a38590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 0.7678 MSE val: 1.1136 MSE test: 0.7100\n"
     ]
    }
   ],
   "source": [
    "signatures_X, signatures_Y, signatures_Y_pred, sig_Y = sig_lreg(sig_X, sig_Y, data, 528, alpha=0.1, normalize_sig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e2342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_size = sig_X(torch.zeros_like(data['X_train'][:1])).shape[1]\n",
    "data_size = 1\n",
    "cvector_size = 84\n",
    "initial_noise_size = 16\n",
    "hidden_size = 92\n",
    "architectures = {'initial': [32], 'drift': [32, 32, 32, 32, 32], 'diffusion': [32, 32, 32, 32, 32]}\n",
    "t_norm=None\n",
    "noise_size = 10\n",
    "noise_type = 'general'\n",
    "final_tanh = True\n",
    "proj = False\n",
    "translation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e8fba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:      79273\n"
     ]
    }
   ],
   "source": [
    "G = SigNSDE(sig_size, data_size, cvector_size, initial_noise_size, hidden_size, architectures, t_norm, \n",
    "            noise_size, noise_type, final_tanh, proj, translation).to(device)\n",
    "\n",
    "print(f\"Total number of parameters: {get_n_params(G):10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b605f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = torch.optim.Adadelta(G.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "509efd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {'nsamples_fs': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35dde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = np.arange(10, 600, 10).tolist()\n",
    "batch_size_time = torch.zeros([len(batch_size), 25])\n",
    "batch_size_memory = torch.zeros([len(batch_size), 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1832e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = data['Y_train'][:, :, 1:].shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc175eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(batch_size)):\n",
    "    batch_size_ = batch_size[i]\n",
    "    train_dataset = TensorDataset(signatures_X['train'], data['X_train'][:, :, 1:], signatures_Y_pred['train'])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size = batch_size_, shuffle=True)\n",
    "    infinite_dataloader = (elem for it in iter(lambda: train_dataloader, None) for elem in it)\n",
    "\n",
    "    G = G.to(device)\n",
    "\n",
    "    for step in range(25):\n",
    "        start_time = time()\n",
    "        G_optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "        sig_X_batch, X_batch, sigY_pred_batch = next(infinite_dataloader) \n",
    "        X_batch = X_batch[:, -1:, :]\n",
    "        X_batch_mc = X_batch.repeat(hp['nsamples_fs'], 1, 1).requires_grad_().to(device, non_blocking=True)\n",
    "        sig_X_batch_mc = sig_X_batch.repeat(hp['nsamples_fs'], 1).requires_grad_().to(device, non_blocking=True)\n",
    "            \n",
    "        del sig_X_batch, X_batch\n",
    "    \n",
    "        Y_batch_pred = G(sig_X_batch_mc, X_batch_mc, q)\n",
    "        del X_batch_mc, sig_X_batch_mc      \n",
    "        t = torch.arange(0, Y_batch_pred.shape[1]).repeat(Y_batch_pred.shape[0]).view(Y_batch_pred.shape[0], \n",
    "                                                                                                  Y_batch_pred.shape[1], 1).to(device, non_blocking=True)\n",
    "        Y_batch_pred_t = torch.cat([t, Y_batch_pred], dim=2)\n",
    "    \n",
    "        del Y_batch_pred, t\n",
    "        sigY_pred_batch = sigY_pred_batch.to(device, non_blocking=True) \n",
    "            \n",
    "        loss = torch.sum(torch.norm(torch.mean(sig_Y(Y_batch_pred_t).view(hp['nsamples_fs'], sigY_pred_batch.shape[0], sigY_pred_batch.shape[1]), dim=0)-sigY_pred_batch, p=2, dim=1))\n",
    "        \n",
    "        loss.backward()\n",
    "        del Y_batch_pred_t\n",
    "        del loss\n",
    "        \n",
    "        G_optimizer.step()\n",
    "        G_optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        end_time = time()\n",
    "        batch_size_time[i, step] = end_time-start_time\n",
    "        batch_size_memory[i, step] = torch.cuda.max_memory_allocated(device='cuda')*1e-6\n",
    "        torch.cuda.reset_max_memory_allocated(device='cuda')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47038485",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_size_time, 'batch_size_time.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1df2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_size_memory, 'batch_size_memory.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea7778a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_size = sig_X(torch.zeros_like(data['X_train'][:1])).shape[1]\n",
    "data_size = 1\n",
    "cvector_size = 32\n",
    "initial_noise_size = 16\n",
    "hidden_size = 48\n",
    "architectures = {'initial': [32], 'drift': [84], 'diffusion': [84]}\n",
    "t_norm=None\n",
    "noise_size = 8\n",
    "noise_type = 'diagonal'\n",
    "final_tanh = True\n",
    "proj = False\n",
    "translation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b8b0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:      29161\n"
     ]
    }
   ],
   "source": [
    "G = SigNSDE(sig_size, data_size, cvector_size, initial_noise_size, hidden_size, architectures, t_norm, \n",
    "            noise_size, noise_type, final_tanh, proj, translation).to(device)\n",
    "\n",
    "print(f\"Total number of parameters: {get_n_params(G):10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f0905cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = torch.optim.Adadelta(G.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e00236ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = np.arange(10, 600, 10).tolist()\n",
    "batch_size_time = torch.zeros([len(batch_size), 25])\n",
    "batch_size_memory = torch.zeros([len(batch_size), 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c66b69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = data['Y_train'][:, :, 1:].shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c1184ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(batch_size)):\n",
    "    batch_size_ = batch_size[i]\n",
    "    train_dataset = TensorDataset(signatures_X['train'], data['X_train'][:, :, 1:], signatures_Y_pred['train'])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size = batch_size_, shuffle=True)\n",
    "    infinite_dataloader = (elem for it in iter(lambda: train_dataloader, None) for elem in it)\n",
    "\n",
    "    G = G.to(device)\n",
    "\n",
    "    for step in range(25):\n",
    "        start_time = time()\n",
    "        G_optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "        sig_X_batch, X_batch, sigY_pred_batch = next(infinite_dataloader) \n",
    "        X_batch = X_batch[:, -1:, :]\n",
    "        X_batch_mc = X_batch.repeat(hp['nsamples_fs'], 1, 1).requires_grad_().to(device, non_blocking=True)\n",
    "        sig_X_batch_mc = sig_X_batch.repeat(hp['nsamples_fs'], 1).requires_grad_().to(device, non_blocking=True)\n",
    "            \n",
    "        del sig_X_batch, X_batch\n",
    "    \n",
    "        Y_batch_pred = G(sig_X_batch_mc, X_batch_mc, q)\n",
    "        del X_batch_mc, sig_X_batch_mc      \n",
    "        t = torch.arange(0, Y_batch_pred.shape[1]).repeat(Y_batch_pred.shape[0]).view(Y_batch_pred.shape[0], \n",
    "                                                                                                  Y_batch_pred.shape[1], 1).to(device, non_blocking=True)\n",
    "        Y_batch_pred_t = torch.cat([t, Y_batch_pred], dim=2)\n",
    "    \n",
    "        del Y_batch_pred, t\n",
    "        sigY_pred_batch = sigY_pred_batch.to(device, non_blocking=True) \n",
    "            \n",
    "        loss = torch.sum(torch.norm(torch.mean(sig_Y(Y_batch_pred_t).view(hp['nsamples_fs'], sigY_pred_batch.shape[0], sigY_pred_batch.shape[1]), dim=0)-sigY_pred_batch, p=2, dim=1))\n",
    "        \n",
    "        loss.backward()\n",
    "        del Y_batch_pred_t\n",
    "        del loss\n",
    "        \n",
    "        G_optimizer.step()\n",
    "        G_optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        end_time = time()\n",
    "        batch_size_time[i, step] = end_time-start_time\n",
    "        batch_size_memory[i, step] = torch.cuda.max_memory_allocated(device='cuda')*1e-6\n",
    "        torch.cuda.reset_max_memory_allocated(device='cuda')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0dab433",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_size_time, 'batch_size_time_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcd6caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_size_memory, 'batch_size_memory_2.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
