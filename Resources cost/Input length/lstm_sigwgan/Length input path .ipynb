{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd29cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if is_cuda else 'cpu'\n",
    "if not is_cuda:\n",
    "    print(\"Warning: CUDA not available; falling back to CPU but this is likely to be very slow.\")\n",
    "    \n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64045658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('../data.pt')\n",
    "\n",
    "for dataset in data:\n",
    "    data[dataset] = data[dataset].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6665d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.Signature import Signature, Basepoint, sig_lreg, LeadLag, Cumsum2\n",
    "from lib.Baseline import ConditionalGenerator\n",
    "from lib.Utilities import get_n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc90a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {'nsamples_fs': 100, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276a336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_length = np.arange(2, 400, 20).tolist()\n",
    "x_length_time = torch.zeros([len(x_length), 25])\n",
    "x_length_memory = torch.zeros([len(x_length), 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1810379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_length)):\n",
    "    \n",
    "    x_length_ = x_length[i]\n",
    "    data_ = {}\n",
    "    for dataset in data:\n",
    "        if dataset in ['X_train', 'X_val', 'X_test']:\n",
    "            data_[dataset] = torch.clone(data[dataset][:, -x_length_:])\n",
    "        else:\n",
    "            data_[dataset] = torch.clone(data[dataset])\n",
    "    \n",
    "    print(data_['X_train'].shape)\n",
    "    \n",
    "    sig_X = Signature(depth=5, augmentations = [Basepoint, Cumsum2], \n",
    "                  data_size=data_['X_train'].shape[2],\n",
    "                  interval=[0, data_['X_train'].shape[1]+1], \n",
    "                  q=1, \n",
    "                  t_norm = data_['X_train'][:, :, 0].max()).to(device)\n",
    "\n",
    "    sig_Y = Signature(depth=4, augmentations = [Cumsum2], \n",
    "                  data_size=data_['Y_train'].shape[2],\n",
    "                  interval=[0, data_['Y_train'].shape[1]+1], \n",
    "                  q=1, \n",
    "                  t_norm = data_['Y_train'][:, :, 0].max()).to(device)\n",
    "    \n",
    "    signatures_X, signatures_Y, signatures_Y_pred, sig_Y = sig_lreg(sig_X, sig_Y, data_, 528, alpha=0.1, normalize_sig = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    G = ConditionalGenerator(1, 1, 32, 5, 5).to('cuda')\n",
    "    \n",
    "    G_optimizer = torch.optim.Adam(G.parameters(), lr=1e-3)\n",
    "\n",
    "    q = data_['Y_train'].shape[1]-1\n",
    "\n",
    "    train_dataset = TensorDataset(data_['X_train'][:, :, 1:], signatures_Y_pred['train'])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size = hp['batch_size'], shuffle=True)\n",
    "    infinite_dataloader = (elem for it in iter(lambda: train_dataloader, None) for elem in it)\n",
    "\n",
    "    for step in range(25):\n",
    "        start_time = time()\n",
    "        \n",
    "        G_optimizer.zero_grad()\n",
    "        X_batch, sigY_pred_batch = next(infinite_dataloader) \n",
    "        X_batch_mc = X_batch.repeat(hp['nsamples_fs'], 1, 1).requires_grad_().to(device)\n",
    "        del X_batch\n",
    "        Y_batch_pred = G(X_batch_mc, q)\n",
    "        del X_batch_mc\n",
    "        t = torch.arange(0, Y_batch_pred.shape[1]).repeat(Y_batch_pred.shape[0]).view(Y_batch_pred.shape[0], Y_batch_pred.shape[1], 1).to(device)\n",
    "        Y_batch_pred_t = torch.cat([t, Y_batch_pred], dim=2)\n",
    "        del t\n",
    "        \n",
    "        sigY_batch = sig_Y(Y_batch_pred_t).view(hp['nsamples_fs'], sigY_pred_batch.shape[0], sigY_pred_batch.shape[1])\n",
    "        del Y_batch_pred_t\n",
    "        sigY_batch_mean = torch.mean(sigY_batch, dim=0)\n",
    "        del sigY_batch\n",
    "        sigY_pred_batch = sigY_pred_batch.to(device)\n",
    "        loss = torch.sum(torch.norm(sigY_batch_mean-sigY_pred_batch, p=2, dim=1))\n",
    "        loss.backward()\n",
    "        del sigY_pred_batch, sigY_batch_mean\n",
    "\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        end_time = time()\n",
    "        x_length_time[i, step] = end_time-start_time\n",
    "        x_length_memory[i, step] = torch.cuda.max_memory_allocated(device='cuda')*1e-6\n",
    "        torch.cuda.reset_max_memory_allocated(device='cuda')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74271515",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.mean(x_length_time, dim=1)[:18], 'x_length_time.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0e5c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.mean(x_length_memory, dim=1)[:18], 'x_length_memory.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
