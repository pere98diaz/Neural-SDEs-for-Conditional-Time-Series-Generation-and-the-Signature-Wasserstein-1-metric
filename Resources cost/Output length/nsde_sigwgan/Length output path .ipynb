{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd29cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if is_cuda else 'cpu'\n",
    "if not is_cuda:\n",
    "    print(\"Warning: CUDA not available; falling back to CPU but this is likely to be very slow.\")\n",
    "    \n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64045658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('../data.pt')\n",
    "\n",
    "for dataset in data:\n",
    "    data[dataset] = data[dataset].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.Signature import Signature, Basepoint, sig_lreg, Cumsum2\n",
    "from lib.NSDE import SigNSDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc90a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {'nsamples_fs': 100, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1\n",
    "cvector_size = 84\n",
    "initial_noise_size = 16\n",
    "hidden_size = 92\n",
    "architectures = {'initial': [32], 'drift': [32, 32, 32, 32, 32], 'diffusion': [32, 32, 32, 32, 32]}\n",
    "t_norm=None\n",
    "noise_size = 10\n",
    "noise_type = 'general'\n",
    "final_tanh = True\n",
    "proj = False\n",
    "translation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_length = np.arange(2, 400, 20).tolist()\n",
    "y_length[0] = 3\n",
    "y_length_time = torch.zeros([len(y_length), 25])\n",
    "y_length_memory = torch.zeros([len(y_length), 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85316bde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_length)):\n",
    "    \n",
    "    y_length_ = y_length[i]\n",
    "    data_ = {}\n",
    "    for dataset in data:\n",
    "        if dataset in ['Y_train', 'Y_val', 'Y_test']:\n",
    "            data_[dataset] = torch.clone(data[dataset][:, :y_length_])\n",
    "        else:\n",
    "            data_[dataset] = torch.clone(data[dataset])\n",
    "    \n",
    "    print(data_['Y_train'].shape)\n",
    "    sig_X = Signature(depth=5, augmentations = [Basepoint, Cumsum2], \n",
    "                  data_size=data_['X_train'].shape[2],\n",
    "                  interval=[0, data_['X_train'].shape[1]+1], \n",
    "                  q=1, \n",
    "                  t_norm = data_['X_train'][:, :, 0].max()).to(device)\n",
    "\n",
    "    sig_Y = Signature(depth=4, augmentations = [Cumsum2], \n",
    "                  data_size=data_['Y_train'].shape[2],\n",
    "                  interval=[0, data_['Y_train'].shape[1]+1], \n",
    "                  q=1, \n",
    "                  t_norm = data_['Y_train'][:, :, 0].max()).to(device)\n",
    "    \n",
    "    sig_size = sig_X(torch.zeros_like(data_['X_train'][:1])).shape[1]\n",
    "    \n",
    "    signatures_X, signatures_Y, signatures_Y_pred, sig_Y = sig_lreg(sig_X, sig_Y, data_, 528, alpha=0.1, normalize_sig = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    G = SigNSDE(sig_size, data_size, cvector_size, initial_noise_size, hidden_size, architectures, t_norm, \n",
    "            noise_size, noise_type, final_tanh, proj, translation).to(device)\n",
    "    \n",
    "    G_optimizer = torch.optim.Adam(G.parameters(), lr=1e-3)\n",
    "\n",
    "    q = data_['Y_train'].shape[1]-1\n",
    "\n",
    "    train_dataset = TensorDataset(signatures_X['train'], data_['X_train'][:, :, 1:], signatures_Y_pred['train'])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size = hp['batch_size'], shuffle=True)\n",
    "    infinite_dataloader = (elem for it in iter(lambda: train_dataloader, None) for elem in it)\n",
    "\n",
    "    trange = tqdm(range(25))\n",
    "    for step in trange:\n",
    "        start_time = time()\n",
    "        \n",
    "        G_optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "        sig_X_batch, X_batch, sigY_pred_batch = next(infinite_dataloader)\n",
    "        X_batch = X_batch[:, -1:, :]\n",
    "        X_batch_mc = X_batch.repeat(hp['nsamples_fs'], 1, 1).requires_grad_().to(device, non_blocking=True)\n",
    "        sig_X_batch_mc = sig_X_batch.repeat(hp['nsamples_fs'], 1).requires_grad_().to(device, non_blocking=True)\n",
    "            \n",
    "        del sig_X_batch, X_batch\n",
    "    \n",
    "        Y_batch_pred = G(sig_X_batch_mc, X_batch_mc, q)\n",
    "        del X_batch_mc, sig_X_batch_mc      \n",
    "        t = torch.arange(0, Y_batch_pred.shape[1]).repeat(Y_batch_pred.shape[0]).view(Y_batch_pred.shape[0], \n",
    "                                                                                                  Y_batch_pred.shape[1], 1).to(device, non_blocking=True)\n",
    "        Y_batch_pred_t = torch.cat([t, Y_batch_pred], dim=2)\n",
    "    \n",
    "        del Y_batch_pred, t\n",
    "        sigY_pred_batch = sigY_pred_batch.to(device, non_blocking=True) \n",
    "            \n",
    "        loss = torch.sum(torch.norm(torch.mean(sig_Y(Y_batch_pred_t).view(hp['nsamples_fs'], sigY_pred_batch.shape[0], \n",
    "                                                                          sigY_pred_batch.shape[1]), dim=0)-sigY_pred_batch, \n",
    "                                    p=2, dim=1))\n",
    "\n",
    "        loss.backward()\n",
    "        del Y_batch_pred_t\n",
    "        del loss\n",
    "        \n",
    "        G_optimizer.step()\n",
    "        G_optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        end_time = time()\n",
    "        y_length_time[i, step] = end_time-start_time\n",
    "        y_length_memory[i, step] = torch.cuda.max_memory_allocated(device='cuda')*1e-6\n",
    "        torch.cuda.reset_max_memory_allocated(device='cuda')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.mean(y_length_time, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74271515",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.mean(y_length_time, dim=1), 'y_length_time.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.mean(y_length_memory, dim=1), 'y_length_memory.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_size = sig_X(torch.zeros_like(data['X_train'][:1])).shape[1]\n",
    "data_size = 1\n",
    "cvector_size = 32\n",
    "initial_noise_size = 16\n",
    "hidden_size = 48\n",
    "architectures = {'initial': [32], 'drift': [84], 'diffusion': [84]}\n",
    "t_norm=None\n",
    "noise_size = 8\n",
    "noise_type = 'diagonal'\n",
    "final_tanh = True\n",
    "proj = False\n",
    "translation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_length = np.arange(2, 400, 20).tolist()\n",
    "y_length[0] = 3\n",
    "y_length_time = torch.zeros([len(y_length), 25])\n",
    "y_length_memory = torch.zeros([len(y_length), 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f3857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_length)):\n",
    "    \n",
    "    y_length_ = y_length[i]\n",
    "    data_ = {}\n",
    "    for dataset in data:\n",
    "        if dataset in ['Y_train', 'Y_val', 'Y_test']:\n",
    "            data_[dataset] = torch.clone(data[dataset][:, :y_length_])\n",
    "        else:\n",
    "            data_[dataset] = torch.clone(data[dataset])\n",
    "    \n",
    "    print(data_['Y_train'].shape)\n",
    "    sig_X = Signature(depth=5, augmentations = [Basepoint, Cumsum2], \n",
    "                  data_size=data_['X_train'].shape[2],\n",
    "                  interval=[0, data_['X_train'].shape[1]+1], \n",
    "                  q=1, \n",
    "                  t_norm = data_['X_train'][:, :, 0].max()).to(device)\n",
    "\n",
    "    sig_Y = Signature(depth=4, augmentations = [Cumsum2], \n",
    "                  data_size=data_['Y_train'].shape[2],\n",
    "                  interval=[0, data_['Y_train'].shape[1]+1], \n",
    "                  q=1, \n",
    "                  t_norm = data_['Y_train'][:, :, 0].max()).to(device)\n",
    "    \n",
    "    sig_size = sig_X(torch.zeros_like(data_['X_train'][:1])).shape[1]\n",
    "    \n",
    "    signatures_X, signatures_Y, signatures_Y_pred, sig_Y = sig_lreg(sig_X, sig_Y, data_, 528, alpha=0.1, normalize_sig = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    G = SigNSDE(sig_size, data_size, cvector_size, initial_noise_size, hidden_size, architectures, t_norm, \n",
    "            noise_size, noise_type, final_tanh, proj, translation).to(device)\n",
    "    \n",
    "    G_optimizer = torch.optim.Adam(G.parameters(), lr=1e-3)\n",
    "\n",
    "    q = data_['Y_train'].shape[1]-1\n",
    "\n",
    "    train_dataset = TensorDataset(signatures_X['train'], data_['X_train'][:, :, 1:], signatures_Y_pred['train'])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size = hp['batch_size'], shuffle=True)\n",
    "    infinite_dataloader = (elem for it in iter(lambda: train_dataloader, None) for elem in it)\n",
    "\n",
    "    # Train both generator and discriminator.\n",
    "    trange = tqdm(range(25))\n",
    "    for step in trange:\n",
    "        start_time = time()\n",
    "        \n",
    "        G_optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "        sig_X_batch, X_batch, sigY_pred_batch = next(infinite_dataloader) # Get next batch of signatures of real path\n",
    "        X_batch = X_batch[:, -1:, :]\n",
    "        X_batch_mc = X_batch.repeat(hp['nsamples_fs'], 1, 1).requires_grad_().to(device, non_blocking=True)\n",
    "        sig_X_batch_mc = sig_X_batch.repeat(hp['nsamples_fs'], 1).requires_grad_().to(device, non_blocking=True)\n",
    "            \n",
    "        del sig_X_batch, X_batch\n",
    "    \n",
    "        Y_batch_pred = G(sig_X_batch_mc, X_batch_mc, q)\n",
    "        del X_batch_mc, sig_X_batch_mc      \n",
    "        t = torch.arange(0, Y_batch_pred.shape[1]).repeat(Y_batch_pred.shape[0]).view(Y_batch_pred.shape[0], \n",
    "                                                                                                  Y_batch_pred.shape[1], 1).to(device, non_blocking=True)\n",
    "        Y_batch_pred_t = torch.cat([t, Y_batch_pred], dim=2)\n",
    "    \n",
    "        del Y_batch_pred, t\n",
    "        sigY_pred_batch = sigY_pred_batch.to(device, non_blocking=True) \n",
    "            \n",
    "        loss = torch.sum(torch.norm(torch.mean(sig_Y(Y_batch_pred_t).view(hp['nsamples_fs'], sigY_pred_batch.shape[0], \n",
    "                                                                          sigY_pred_batch.shape[1]), dim=0)-sigY_pred_batch, \n",
    "                                    p=2, dim=1))\n",
    "\n",
    "        loss.backward()\n",
    "        del Y_batch_pred_t\n",
    "        del loss\n",
    "        \n",
    "        G_optimizer.step()\n",
    "        G_optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        end_time = time()\n",
    "        y_length_time[i, step] = end_time-start_time\n",
    "        y_length_memory[i, step] = torch.cuda.max_memory_allocated(device='cuda')*1e-6\n",
    "        torch.cuda.reset_max_memory_allocated(device='cuda')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.mean(y_length_time, dim=1), 'y_length_time_2.pt')\n",
    "torch.save(torch.mean(y_length_memory, dim=1), 'y_length_memory_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17129d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
